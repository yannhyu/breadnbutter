https://hub.docker.com/r/sequenceiq/hadoop-docker/

+++++++++++++++++++++++++++++++++++++++++++++++++

airflow@mllxv-yu:~/pythoncode/hadoop-docker$ ls
bootstrap.sh  core-site.xml.template  Dockerfile  hdfs-site.xml  LICENSE  mapred-site.xml  README.md  ssh_config  yarn-site.xml
airflow@mllxv-yu:~/pythoncode/hadoop-docker$ 


+++++++++++++++++++++++++++++++++++++++++++++++++

airflow@mllxv-yu:~/pythoncode/hadoop-docker$ docker run -it sequenceiq/hadoop-docker:2.7.0 /etc/bootstrap.sh -bash
/
Starting sshd:                                             [  OK  ]
16/12/19 13:34:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Starting namenodes on [49f92d5664fb]
49f92d5664fb: starting namenode, logging to /usr/local/hadoop/logs/hadoop-root-namenode-49f92d5664fb.out
localhost: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-49f92d5664fb.out
Starting secondary namenodes [0.0.0.0]
0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-root-secondarynamenode-49f92d5664fb.out
16/12/19 13:34:51 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
starting yarn daemons
starting resourcemanager, logging to /usr/local/hadoop/logs/yarn--resourcemanager-49f92d5664fb.out
localhost: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-49f92d5664fb.out
chown: missing operand after `/usr/local/hadoop/logs'
Try `chown --help' for more information.
starting historyserver, logging to /usr/local/hadoop/logs/mapred--historyserver-49f92d5664fb.out
bash-4.1# whoami
root
bash-4.1# pwd
/
bash-4.1# echo $HADOOP_PREFIX
/usr/local/hadoop
bash-4.1# bin/hdfs dfs -cat output/*
bash: bin/hdfs: No such file or directory
bash-4.1# 

+++++++++++++++++++++++++++++++++++++++++++++++++

bash-4.1# bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output 'dfs[a-z.]+'
16/12/19 13:41:40 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/12/19 13:41:40 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/12/19 13:41:42 INFO input.FileInputFormat: Total input paths to process : 31
16/12/19 13:41:42 INFO mapreduce.JobSubmitter: number of splits:31
16/12/19 13:41:42 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1482172493872_0001
16/12/19 13:41:43 INFO impl.YarnClientImpl: Submitted application application_1482172493872_0001
16/12/19 13:41:43 INFO mapreduce.Job: The url to track the job: http://49f92d5664fb:8088/proxy/application_1482172493872_0001/
16/12/19 13:41:43 INFO mapreduce.Job: Running job: job_1482172493872_0001
16/12/19 13:41:50 INFO mapreduce.Job: Job job_1482172493872_0001 running in uber mode : false
16/12/19 13:41:50 INFO mapreduce.Job:  map 0% reduce 0%
16/12/19 13:42:04 INFO mapreduce.Job:  map 10% reduce 0%
16/12/19 13:42:05 INFO mapreduce.Job:  map 19% reduce 0%
16/12/19 13:42:16 INFO mapreduce.Job:  map 26% reduce 0%
16/12/19 13:42:17 INFO mapreduce.Job:  map 39% reduce 0%
16/12/19 13:42:28 INFO mapreduce.Job:  map 42% reduce 13%
16/12/19 13:42:29 INFO mapreduce.Job:  map 55% reduce 13%
16/12/19 13:42:31 INFO mapreduce.Job:  map 55% reduce 18%
16/12/19 13:42:38 INFO mapreduce.Job:  map 68% reduce 18%
16/12/19 13:42:39 INFO mapreduce.Job:  map 71% reduce 18%
16/12/19 13:42:40 INFO mapreduce.Job:  map 71% reduce 24%
16/12/19 13:42:48 INFO mapreduce.Job:  map 84% reduce 24%
16/12/19 13:42:49 INFO mapreduce.Job:  map 87% reduce 28%
16/12/19 13:42:52 INFO mapreduce.Job:  map 87% reduce 29%
16/12/19 13:42:56 INFO mapreduce.Job:  map 100% reduce 29%
16/12/19 13:42:57 INFO mapreduce.Job:  map 100% reduce 100%
16/12/19 13:42:57 INFO mapreduce.Job: Job job_1482172493872_0001 completed successfully
16/12/19 13:42:57 INFO mapreduce.Job: Counters: 49
    File System Counters
        FILE: Number of bytes read=345
        FILE: Number of bytes written=3722244
        FILE: Number of read operations=0
        FILE: Number of large read operations=0
        FILE: Number of write operations=0
        HDFS: Number of bytes read=80529
        HDFS: Number of bytes written=437
        HDFS: Number of read operations=96
        HDFS: Number of large read operations=0
        HDFS: Number of write operations=2
    Job Counters 
        Launched map tasks=31
        Launched reduce tasks=1
        Data-local map tasks=31
        Total time spent by all maps in occupied slots (ms)=315434
        Total time spent by all reduces in occupied slots (ms)=40086
        Total time spent by all map tasks (ms)=315434
        Total time spent by all reduce tasks (ms)=40086
        Total vcore-seconds taken by all map tasks=315434
        Total vcore-seconds taken by all reduce tasks=40086
        Total megabyte-seconds taken by all map tasks=323004416
        Total megabyte-seconds taken by all reduce tasks=41048064
    Map-Reduce Framework
        Map input records=2060
        Map output records=24
        Map output bytes=590
        Map output materialized bytes=525
        Input split bytes=3812
        Combine input records=24
        Combine output records=13
        Reduce input groups=11
        Reduce shuffle bytes=525
        Reduce input records=13
        Reduce output records=11
        Spilled Records=26
        Shuffled Maps =31
        Failed Shuffles=0
        Merged Map outputs=31
        GC time elapsed (ms)=2193
        CPU time spent (ms)=9420
        Physical memory (bytes) snapshot=7725248512
        Virtual memory (bytes) snapshot=23198240768
        Total committed heap usage (bytes)=5979504640
    Shuffle Errors
        BAD_ID=0
        CONNECTION=0
        IO_ERROR=0
        WRONG_LENGTH=0
        WRONG_MAP=0
        WRONG_REDUCE=0
    File Input Format Counters 
        Bytes Read=76717
    File Output Format Counters 
        Bytes Written=437
16/12/19 13:42:57 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/12/19 13:42:57 INFO input.FileInputFormat: Total input paths to process : 1
16/12/19 13:42:57 INFO mapreduce.JobSubmitter: number of splits:1
16/12/19 13:42:58 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1482172493872_0002
16/12/19 13:42:58 INFO impl.YarnClientImpl: Submitted application application_1482172493872_0002
16/12/19 13:42:58 INFO mapreduce.Job: The url to track the job: http://49f92d5664fb:8088/proxy/application_1482172493872_0002/
16/12/19 13:42:58 INFO mapreduce.Job: Running job: job_1482172493872_0002
16/12/19 13:43:08 INFO mapreduce.Job: Job job_1482172493872_0002 running in uber mode : false
16/12/19 13:43:08 INFO mapreduce.Job:  map 0% reduce 0%
16/12/19 13:43:12 INFO mapreduce.Job:  map 100% reduce 0%
16/12/19 13:43:18 INFO mapreduce.Job:  map 100% reduce 100%
16/12/19 13:43:18 INFO mapreduce.Job: Job job_1482172493872_0002 completed successfully
16/12/19 13:43:18 INFO mapreduce.Job: Counters: 49
    File System Counters
        FILE: Number of bytes read=291
        FILE: Number of bytes written=232089
        FILE: Number of read operations=0
        FILE: Number of large read operations=0
        FILE: Number of write operations=0
        HDFS: Number of bytes read=568
        HDFS: Number of bytes written=197
        HDFS: Number of read operations=7
        HDFS: Number of large read operations=0
        HDFS: Number of write operations=2
    Job Counters 
        Launched map tasks=1
        Launched reduce tasks=1
        Data-local map tasks=1
        Total time spent by all maps in occupied slots (ms)=2462
        Total time spent by all reduces in occupied slots (ms)=2727
        Total time spent by all map tasks (ms)=2462
        Total time spent by all reduce tasks (ms)=2727
        Total vcore-seconds taken by all map tasks=2462
        Total vcore-seconds taken by all reduce tasks=2727
        Total megabyte-seconds taken by all map tasks=2521088
        Total megabyte-seconds taken by all reduce tasks=2792448
    Map-Reduce Framework
        Map input records=11
        Map output records=11
        Map output bytes=263
        Map output materialized bytes=291
        Input split bytes=131
        Combine input records=0
        Combine output records=0
        Reduce input groups=5
        Reduce shuffle bytes=291
        Reduce input records=11
        Reduce output records=11
        Spilled Records=22
        Shuffled Maps =1
        Failed Shuffles=0
        Merged Map outputs=1
        GC time elapsed (ms)=44
        CPU time spent (ms)=980
        Physical memory (bytes) snapshot=433364992
        Virtual memory (bytes) snapshot=1458565120
        Total committed heap usage (bytes)=326107136
    Shuffle Errors
        BAD_ID=0
        CONNECTION=0
        IO_ERROR=0
        WRONG_LENGTH=0
        WRONG_MAP=0
        WRONG_REDUCE=0
    File Input Format Counters 
        Bytes Read=437
    File Output Format Counters 
        Bytes Written=197
bash-4.1# 

+++++++++++++++++++++++++++++++++++++++++++++++++

bash-4.1# bin/hdfs dfs -cat output/*
16/12/19 13:45:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
6   dfs.audit.logger
4   dfs.class
3   dfs.server.namenode.
2   dfs.period
2   dfs.audit.log.maxfilesize
2   dfs.audit.log.maxbackupindex
1   dfsmetrics.log
1   dfsadmin
1   dfs.servers
1   dfs.replication
1   dfs.file
bash-4.1# 


+++++++++++++++++++++++++++++++++++++++++++++++++



Build the image
If you'd like to try directly from the Dockerfile you can build the image as:

docker build  -t sequenceiq/hadoop-docker:2.7.0 .
Pull the image
The image is also released as an official Docker image from Docker's automated build repository - you can always pull or refer the image when launching containers.

docker pull sequenceiq/hadoop-docker:2.7.0
Start a container
In order to use the Docker image you have just build or pulled use:

Make sure that SELinux is disabled on the host. If you are using boot2docker you don't need to do anything.

docker run -it sequenceiq/hadoop-docker:2.7.0 /etc/bootstrap.sh -bash
Testing
You can run one of the stock examples:

cd $HADOOP_PREFIX
# run the mapreduce
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.0.jar grep input output 'dfs[a-z.]+'

# check the output
bin/hdfs dfs -cat output/*


++++++++++++++++++++++++++++++++++++++++++++++++++++++++